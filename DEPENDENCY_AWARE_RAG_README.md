# Reasoning-First Dependency-Aware RAG System

A sophisticated Retrieval-Augmented Generation (RAG) pipeline that intelligently identifies when external links need to be fetched to answer questions, processes various content types (JSON/HTML/text), and enriches context for improved reasoning.

## üéØ Key Features

- **Two-stage dependency classification** (fast rules + LLM checkpoint)
- **Concurrent link fetching** with caching and timeout handling  
- **Enhanced content processing** for JSON, HTML, and text responses
- **Security validation** for URLs and domains
- **Comprehensive logging** and auditing of reasoning steps
- **Robust error handling** with fallback mechanisms
- **HackRx puzzle compatibility** for procedural multi-step reasoning

## üèóÔ∏è Architecture

### Core Components

1. **DependencyManager** - Main orchestrator for dependency-aware processing
2. **LinkDependency** - Data class representing extracted links with context
3. **Two-stage classifier** - Efficient dependency determination
4. **Content processors** - Specialized handling for different content types
5. **Caching layer** - LRU cache for link content

### Processing Pipeline

```
Document Input ‚Üí Link Extraction ‚Üí Dependency Classification ‚Üí Link Fetching ‚Üí Context Enrichment ‚Üí Answer Generation
```

## üöÄ Quick Start

### Installation

```bash
# Install additional dependencies for enhanced features
pip install beautifulsoup4 aiohttp

# Or add to requirements.txt:
# beautifulsoup4>=4.12.0
# aiohttp>=3.8.0
```

### Basic Usage

```python
from app.services.depedency_aware_retrieval import DependencyManager

# Initialize the dependency manager
dependency_manager = DependencyManager(
    max_concurrent_requests=3,
    request_timeout=10,
    enable_security_checks=True
)

# Process dependencies for a question and document chunks
enriched_chunks, dependencies = await dependency_manager.process_dependencies(
    question="What is my flight number?", 
    chunks=document_chunks
)

# Generate answer using enriched context
answer = await generate_answer(question, enriched_chunks)
```

### Running the Demo

```bash
# Run all examples
python run_request_example.py

# Run only HackRx example
python run_request_example.py --mode hackrx

# Run only simple example  
python run_request_example.py --mode simple
```

## üìã Configuration Options

### DependencyManager Parameters

```python
DependencyManager(
    max_concurrent_requests=3,      # Max concurrent link fetches
    request_timeout=10,             # Timeout per request (seconds)
    max_content_length=5000,        # Max content length to process
    enable_security_checks=True     # Enable URL security validation
)
```

### Security Configuration

The system includes built-in security features:

- **URL validation** - Blocks dangerous schemes and private IPs
- **Domain allowlists** - Configurable blocked domains
- **Content length limits** - Prevents memory exhaustion
- **Request timeouts** - Prevents hanging requests

```python
# Configure blocked domains
dependency_manager.blocked_domains.update(['malicious.com', 'spam.net'])

# Configure allowed schemes
dependency_manager.allowed_schemes = {'https'}  # HTTPS only
```

## üîÑ Two-Stage Dependency Classification

### Stage A: Fast Rules-Based Check

Looks for keywords and patterns indicating potential link dependencies:

- **Action keywords**: `fetch`, `download`, `get`, `call`, `invoke`, `api`, `endpoint`
- **Status keywords**: `status`, `submit`, `upload`, `login`, `authenticate`
- **Procedural indicators**: `step`, `first`, `then`, `next`, `before`, `after`

### Stage B: LLM Checkpoint

Uses structured LLM prompt for higher fidelity classification:

```
You are a dependency analyzer. Given the QUESTION and the following retrieved context chunks, decide for each URL whether the assistant MUST visit it (REQUIRED) or can SKIP it.

QUESTION: What is my flight number?

TOP CHUNKS (with URLs):
1) First, call https://register.hackrx.in/submissions/myFavouriteCity to get your assigned city.
2) Call the appropriate endpoint at https://register.hackrx.in/teams/public/flights/{endpoint}

For each URL above, output one line in exactly this format:
Link1: REQUIRED
Link2: SKIP
```

## üåê Content Processing

### JSON Endpoints

- **Full JSON preservation** with pretty-printing
- **Key-value summaries** for first-level keys
- **Array length information** for JSON arrays
- **Graceful fallback** for malformed JSON

Example output:
```
JSON Summary: success: true, message: Favorite city retrieved successfully, data: dict(1 items)

Full JSON:
{
  "success": true,
  "message": "Favorite city retrieved successfully", 
  "status": 200,
  "data": {
    "city": "New York"
  }
}
```

### HTML Pages

- **Title extraction** from `<title>` tags
- **Main content extraction** using semantic selectors (`<main>`, `<article>`)
- **Script/style removal** for cleaner content
- **Content summarization** with length limits

Example output:
```
HTML Title: Welcome to Our API

Content Summary: This API provides access to city data and flight information. Use the endpoints below to get started with your integration...
```

### Plain Text

- **HTML tag removal** for cleaner processing  
- **Whitespace normalization** 
- **Content length limiting** with summaries
- **Artifact removal** (javascript, css references)

## üìù Logging and Auditing

The system provides comprehensive logging for debugging and auditing:

```python
# Each dependency tracks its processing steps
for dep in dependencies:
    if dep.processing_steps:
        for step in dep.processing_steps:
            print(f"{dep.url}: {step}")

# Get processing summary
summary = dependency_manager.get_dependency_summary(dependencies)
print(f"Dependencies: {summary['required']} required, {summary['fetched']} fetched")
```

Example log output:
```
üî¨ Starting two-stage dependency classification
‚ö° Running Stage A classification  
üîç Stage A: Found potential dependencies - proceeding to Stage B
ü§ñ Stage B: Running LLM classification checkpoint
üìä Parsed Stage B response: 1 links marked as REQUIRED
üåê Fetching 1 required links
üîó Fetching: https://register.hackrx.in/submissions/myFavouriteCity
‚úÖ Successfully fetched https://register.hackrx.in/submissions/myFavouriteCity (98 chars)
üìà Enriching context with 1 fetched links
```

## üß™ Testing

### HackRx Example Scenario

The system handles the HackRx puzzle logic:

1. **Question**: "What is my flight number?"
2. **Document contains**: Multi-step instructions with API endpoints
3. **System identifies**: Need to fetch city first, then flight endpoint
4. **Processes**: JSON response from city API
5. **Applies reasoning**: Uses city to determine correct flight endpoint
6. **Returns**: Complete answer citing both sources

### Unit Testing

```python
# Test dependency extraction
dependencies = await dependency_manager.extract_links_from_chunks(test_chunks)
assert len(dependencies) > 0

# Test classification
classified_deps = await dependency_manager.classify_dependencies("What is my status?", dependencies)
required_deps = [dep for dep in classified_deps if dep.is_required]
assert len(required_deps) > 0

# Test content processing
processed = dependency_manager._process_web_content('{"key": "value"}', 'application/json')
assert "JSON Summary" in processed
```

## üîß Integration with Existing RAG Pipeline

### FastAPI Integration

The system is already integrated into the main query endpoint at `app/api/endpoints/query.py`:

```python
# Initialize dependency manager
dependency_manager = DependencyManager(max_concurrent_requests=3, request_timeout=10)

# Apply dependency-aware processing before answer generation
try:
    enriched_chunks, dependencies = await dependency_manager.process_dependencies(question, search_chunk_data)
    
    # Log results
    dep_summary = dependency_manager.get_dependency_summary(dependencies)
    logger.info(f"üìä Dependency processing: {dep_summary}")
    
    # Use enriched chunks for answer generation
    prompt = build_prompt(question, enriched_chunks)
    response = await ask_llm(prompt)
    
except Exception as dep_error:
    logger.error(f"‚ùå Dependency processing failed: {str(dep_error)}")
    # Fallback to original approach
    relevant_chunks = faiss_service.enhance_results(search_results, question)
    prompt = build_prompt(question, relevant_chunks)
    response = await ask_llm(prompt)
```

### Vector Store Compatibility

Works with any vector store that returns chunk data:

```python
# FAISS integration (already implemented)
search_results = faiss_service.multi_tier_search(query_embedding, question, k=20)
search_chunk_data = extract_chunks_from_results(search_results)

# Weaviate integration (example)
search_results = weaviate_client.query.get("Document").with_near_vector(query_embedding).do()
search_chunk_data = [{"text": item["content"]} for item in search_results["data"]["Get"]["Document"]]

# Apply dependency processing
enriched_chunks, dependencies = await dependency_manager.process_dependencies(question, search_chunk_data)
```

## üéõÔ∏è Advanced Configuration

### Custom LLM Integration

```python
# Custom LLM wrapper function
async def custom_ask_llm(prompt: str, max_tokens: int = 512, temperature: float = 0.2) -> str:
    # Your LLM integration here
    return llm_response

# Use with dependency manager
from app.services import llm_service
llm_service.ask_llm = custom_ask_llm
```

### Redis Caching

```python
import redis
import json

class RedisDependencyCache:
    def __init__(self, redis_url: str):
        self.redis_client = redis.from_url(redis_url)
    
    def get(self, key: str):
        cached = self.redis_client.get(key)
        return json.loads(cached) if cached else None
    
    def set(self, key: str, value: dict, ttl: int = 3600):
        self.redis_client.setex(key, ttl, json.dumps(value))

# Replace in-memory cache
dependency_manager.link_cache = RedisDependencyCache("redis://localhost:6379")
```

### Custom Content Processors

```python
# Add custom content processor
def process_xml_content(content: str) -> str:
    # Custom XML processing logic
    return processed_content

# Extend content processing
original_process = dependency_manager._process_web_content

def enhanced_process_content(content: str, content_type: str = ""):
    if 'xml' in content_type.lower():
        return process_xml_content(content)
    return original_process(content, content_type)

dependency_manager._process_web_content = enhanced_process_content
```

## üö® Error Handling

The system includes comprehensive error handling:

### Network Errors
- **Timeouts**: Configurable per-request timeouts
- **Connection errors**: Graceful handling of network failures  
- **HTTP errors**: Proper handling of 4xx/5xx responses

### Content Processing Errors
- **JSON parsing**: Fallback to text processing for malformed JSON
- **HTML parsing**: Graceful degradation without BeautifulSoup
- **Encoding issues**: Proper text encoding handling

### LLM Errors  
- **Classification failures**: Conservative fallback to pattern-based rules
- **Answer generation**: Fallback to original RAG pipeline

### Memory Management
- **Content size limits**: Prevents memory exhaustion
- **Cache size limits**: LRU eviction for memory management
- **Cleanup procedures**: Explicit cleanup of large variables

## üîç Troubleshooting

### Common Issues

1. **No dependencies detected**
   - Check if question contains action keywords
   - Verify link extraction is working correctly
   - Enable debug logging to see classification steps

2. **Links not being fetched**
   - Check URL security validation settings
   - Verify network connectivity to target URLs
   - Check timeout and concurrency settings

3. **Content processing failures**
   - Install optional dependencies (`beautifulsoup4`)
   - Check content type detection logic
   - Enable fallback text processing

4. **Memory usage**
   - Adjust `max_content_length` parameter
   - Implement Redis caching for production
   - Monitor cache size and cleanup

### Debug Logging

```python
import logging
logging.getLogger('app.services.depedency_aware_retrieval').setLevel(logging.DEBUG)

# This will show detailed processing steps:
# - Link extraction results
# - Classification decisions  
# - Fetch attempts and results
# - Content processing steps
# - Context enrichment details
```

## üìä Performance Considerations

### Optimization Tips

1. **Concurrent processing**: Adjust `max_concurrent_requests` based on target server limits
2. **Caching strategy**: Implement Redis for multi-instance deployments
3. **Content limits**: Set appropriate `max_content_length` for your use case
4. **Security checks**: Disable for trusted internal networks if needed
5. **LLM calls**: Consider caching classification results for similar questions

### Benchmarks

- **Classification**: ~100ms for 5 links (including LLM call)
- **Link fetching**: ~200-500ms per link (network dependent)
- **Content processing**: ~10-50ms per response
- **Context enrichment**: ~5ms for 10 chunks

## üõ°Ô∏è Security Considerations

### URL Validation
- Blocks `file://`, `ftp://` schemes by default
- Prevents access to private IP ranges (127.0.0.1, 10.x.x.x, 192.168.x.x)
- Configurable domain blocklist

### Content Sanitization
- HTML tag removal in text processing
- Script/style removal from HTML content
- Content length limits to prevent DoS

### Network Security  
- Request timeouts prevent hanging connections
- SSL/TLS validation (can be disabled for testing)
- Rate limiting via concurrent request limits

## ü§ù Contributing

To extend or modify the system:

1. **Add new content processors** in `_process_web_content`
2. **Extend dependency patterns** in `stage_a_patterns` and `procedural_patterns`
3. **Add new security checks** in `_is_url_safe`
4. **Implement custom caching** by replacing `link_cache`

## üìÑ License

This dependency-aware RAG system is part of the PolicyIntel project and follows the same licensing terms.

---

üéâ **Ready to enhance your RAG pipeline with intelligent dependency awareness!**
